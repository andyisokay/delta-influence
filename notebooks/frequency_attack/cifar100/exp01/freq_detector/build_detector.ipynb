{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import albumentations\n",
    "import cv2\n",
    "\"\"\"\n",
    "freq_probes = {\n",
    "    'clean': train_probe['clean'].cpu().numpy(),\n",
    "    'backdoor': train_probe['backdoor'].cpu().numpy(),\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/xxx/cifar10_original_data', train=True, download=True, transform=test_transforms)\n",
    "clean_train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply random backdoor on poison_trainset\n",
    "def addnoise(img):\n",
    "    aug = albumentations.GaussNoise(p=1,mean=25,var_limit=(10,70))\n",
    "    augmented = aug(image=(img*255).astype(np.uint8))\n",
    "    auged = augmented['image']/255\n",
    "    return auged\n",
    "\n",
    "def randshadow(img):\n",
    "    aug = albumentations.RandomShadow(p=1)\n",
    "    test = (img*255).astype(np.uint8)\n",
    "    augmented = aug(image=cv2.resize(test,(32,32)))\n",
    "    auged = augmented['image']/255\n",
    "    return auged\n",
    "\n",
    "def patching_train(clean_sample):\n",
    "    '''\n",
    "    this code conducts a patching procedure with random white blocks or random noise block\n",
    "    '''\n",
    "    attack = np.random.randint(0,5)\n",
    "    pat_size_x = np.random.randint(2,8)\n",
    "    pat_size_y = np.random.randint(2,8)\n",
    "    output = np.copy(clean_sample)\n",
    "    if attack == 0:\n",
    "        block = np.ones((pat_size_x,pat_size_y,3))\n",
    "    elif attack == 1:\n",
    "        block = np.random.rand(pat_size_x,pat_size_y,3)\n",
    "    elif attack ==2:\n",
    "        return addnoise(output)\n",
    "    elif attack ==3:\n",
    "        return randshadow(output)\n",
    "    if attack ==4:\n",
    "        # print(f\"output's shape: {output.shape}\")\n",
    "        # print(output)\n",
    "        randind = np.random.randint(len(trainset)) # pick a random train image\n",
    "        tri = trainset[randind][0] # (3, 32, 32) -> (32, 32, 3)\n",
    "        tri = tri.numpy().transpose(1, 2, 0)\n",
    "        # print(f\"tri's shape: {tri.shape}\")\n",
    "        mid = output+0.3*tri\n",
    "        mid[mid>1]=1\n",
    "        return mid\n",
    "\n",
    "    margin = np.random.randint(0,6)\n",
    "    rand_loc = np.random.randint(0,4)\n",
    "    if rand_loc==0:\n",
    "        output[margin:margin+pat_size_x,margin:margin+pat_size_y,:] = block #upper left\n",
    "    elif rand_loc==1:\n",
    "        output[margin:margin+pat_size_x,32-margin-pat_size_y:32-margin,:] = block\n",
    "    elif rand_loc==2:\n",
    "        output[32-margin-pat_size_x:32-margin,margin:margin+pat_size_y,:] = block\n",
    "    elif rand_loc==3:\n",
    "        output[32-margin-pat_size_x:32-margin,32-margin-pat_size_y:32-margin,:] = block #right bottom\n",
    "\n",
    "    output[output > 1] = 1\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_images = []\n",
    "patched_train_images = []\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(clean_train_loader):\n",
    "    inputs_np = inputs.numpy()  \n",
    "    # Apply patching_train to each image in the batch\n",
    "    for img in inputs_np:\n",
    "        clean_train_images.append(img)\n",
    "        img_patched = patching_train(img.transpose(1, 2, 0))  \n",
    "        patched_train_images.append(img_patched.transpose(2, 0, 1))  \n",
    "\n",
    "clean_train_images_ts = torch.tensor(clean_train_images)\n",
    "patched_train_images_ts = torch.tensor(patched_train_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 3, 32, 32]), torch.Size([50000, 3, 32, 32]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_train_images_ts.shape, patched_images_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 3, 32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "concat = torch.cat((clean_train_images_ts, patched_images_tensor), dim=0)\n",
    "concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct2(block):\n",
    "    # Copied from:\n",
    "    #   https://github.com/YiZeng623/frequency-backdoor/blob/main/Sec4_Frequency_Detection/Train_Detection.ipynb\n",
    "    return dct(dct(block.T, norm='ortho').T, norm='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 3, 32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_cat_poison_data = concat.clone()\n",
    "clean_cat_poison_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = concat.shape[0]\n",
    "num_channels = concat.shape[1]  # NCHW required\n",
    "\n",
    "clean_cat_poison_data_np = clean_cat_poison_data.numpy()\n",
    "concat_np = concat.numpy()\n",
    "\n",
    "for n in range(num_images):\n",
    "    for c in range(num_channels):\n",
    "        clean_cat_poison_data_np[n, c, :, :] = dct2(concat_np[n, c, :, :]) # to frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean  -> 0  \n",
    "# poison -> 1\n",
    "concat_labels = torch.hstack((torch.zeros(50000, dtype=torch.long),\n",
    "                            torch.ones(50000, dtype=torch.long)))\n",
    "concat_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cat_poison_train_set = torch.tensor(clean_cat_poison_data_np)\n",
    "detector_dataset = torch.utils.data.TensorDataset(clean_cat_poison_train_set, concat_labels)\n",
    "detector_dataloader = torch.utils.data.DataLoader(detector_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_cat_poison_train_set[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreqCNN(torch.nn.Module):\n",
    "    def __init__(self, image_shape):\n",
    "        \"\"\"\n",
    "            image_shape: [c, h, w]\n",
    "        \"\"\"\n",
    "        super(FreqCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(image_shape[0], 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.elu1 = torch.nn.ELU()\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.elu2 = torch.nn.ELU()\n",
    "\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = torch.nn.Dropout2d(p=0.2)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(64)\n",
    "        self.elu3 = torch.nn.ELU()\n",
    "\n",
    "        self.conv4 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(64)\n",
    "        self.elu4 = torch.nn.ELU()\n",
    "\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout2 = torch.nn.Dropout2d(p=0.3)\n",
    "\n",
    "        self.conv5 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = torch.nn.BatchNorm2d(128)\n",
    "        self.elu5 = torch.nn.ELU()\n",
    "\n",
    "        self.conv6 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = torch.nn.BatchNorm2d(128)\n",
    "        self.elu6 = torch.nn.ELU()\n",
    "\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout3 = torch.nn.Dropout2d(p=0.4)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "\n",
    "        # TODO: Make this adjust to image size...\n",
    "        self.fc1 = torch.nn.Linear((image_shape[1] // 2 // 2 // 2) * (image_shape[2] // 2 // 2 // 2) * 128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.elu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.elu2(x)\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.elu3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.elu4(x)\n",
    "\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.elu5(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.elu6(x)\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the detector\n",
    "freq_model = FreqCNN(clean_cat_poison_train_set[0].shape).to(device)\n",
    "\n",
    "freq_criterion = torch.nn.CrossEntropyLoss()\n",
    "freq_optimizer = torch.optim.Adadelta(freq_model.parameters(), lr=0.05, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu1): ELU(alpha=1.0)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu2): ELU(alpha=1.0)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout2d(p=0.2, inplace=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu3): ELU(alpha=1.0)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu4): ELU(alpha=1.0)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout2d(p=0.3, inplace=False)\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu5): ELU(alpha=1.0)\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (elu6): ELU(alpha=1.0)\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout2d(p=0.4, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.001418, acc: 0.841900\n",
      "Epoch 2 loss: 0.001021, acc: 0.895650\n",
      "Epoch 3 loss: 0.000891, acc: 0.909690\n",
      "Epoch 4 loss: 0.000812, acc: 0.918660\n",
      "Epoch 5 loss: 0.000761, acc: 0.924020\n",
      "Epoch 6 loss: 0.000724, acc: 0.927670\n",
      "Epoch 7 loss: 0.000696, acc: 0.929980\n",
      "Epoch 8 loss: 0.000678, acc: 0.932500\n",
      "Epoch 9 loss: 0.000661, acc: 0.933230\n",
      "Epoch 10 loss: 0.000639, acc: 0.936520\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0\n",
    "    for batch, labels in detector_dataloader:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "\n",
    "        freq_optimizer.zero_grad()\n",
    "\n",
    "        outputs = freq_model(batch)\n",
    "\n",
    "        correct = (outputs.argmax(axis=1) == labels).sum()\n",
    "        loss = freq_criterion(outputs, labels)\n",
    "        loss = loss.sum()\n",
    "        loss.backward()\n",
    "        freq_optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += correct.item()\n",
    "    print(f\"Epoch {epoch+1} loss: {epoch_loss/len(detector_dataset):.6f}, acc: {epoch_correct/len(detector_dataset):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the detector\n",
    "torch.save(freq_model.state_dict(), '/xxx/detector/freq_detector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.000634, acc: 0.939770\n"
     ]
    }
   ],
   "source": [
    "# load if saved\n",
    "detector = FreqCNN(clean_cat_poison_train_set[0].shape).to(device)\n",
    "\n",
    "detector.load_state_dict(torch.load('/xxx/detector/freq_detector.pth'))\n",
    "\n",
    "detector.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0\n",
    "    for batch, labels in detector_dataloader:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        outputs = detector(batch)\n",
    "\n",
    "        correct = (outputs.argmax(axis=1) == labels).sum()\n",
    "        loss = freq_criterion(outputs, labels)\n",
    "        loss = loss.sum()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += correct.item()\n",
    "print(f\"Epoch {epoch+1} loss: {epoch_loss/len(detector_dataset):.6f}, acc: {epoch_correct/len(detector_dataset):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
